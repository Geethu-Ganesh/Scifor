{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming and Lemmetization are methods used by search engines and chatbots to analyse the meaning behind a word.\n",
    "# stemming uses the stem of the word ,while lemmetization uses the context in which the word is being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# natural language tool kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer =PorterStemmer()\n",
    "words=['run','ran','write','wrote','written','mostly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-->run\n",
      "ran-->ran\n",
      "write-->write\n",
      "wrote-->wrote\n",
      "written-->written\n",
      "mostly-->mostli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'-->'+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stem=SnowballStemmer(language='english')\n",
    "# the snowball stemmer requires that you pass a language parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('haai', '-->', u'haai')\n",
      "('helow', '-->', u'helow')\n",
      "('bie', '-->', u'bie')\n",
      "('nicely', '-->', u'nice')\n",
      "('badly', '-->', u'bad')\n"
     ]
    }
   ],
   "source": [
    "words=['haai','helow','bie','nicely','badly']\n",
    "for word in words:\n",
    "    print(word,'-->',s_stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairli\n",
      "fair\n"
     ]
    }
   ],
   "source": [
    "print(p_stemmer.stem('fairly'))\n",
    "print(s_stem.stem('fairly'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer\n",
      "('intelligently', '-->', u'intellig')\n",
      "('couragiously', '-->', u'couragi')\n",
      "('Living', '-->', u'live')\n",
      "('Godthings', '-->', u'godth')\n"
     ]
    }
   ],
   "source": [
    "words=['intelligently','couragiously','Living','Godthings']\n",
    "print('Porter Stemmer')\n",
    "for word in words:\n",
    "    print(word,'-->',p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowball Stemmer\n",
      "('intelligently', '-->', u'intellig')\n",
      "('couragiously', '-->', u'couragi')\n",
      "('Living', '-->', u'live')\n",
      "('Godthings', '-->', u'godth')\n"
     ]
    }
   ],
   "source": [
    "words=['intelligently','couragiously','Living','Godthings']\n",
    "print('Snowball Stemmer')\n",
    "for word in words:\n",
    "    print(word,'-->',s_stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming has it's drawbacks. if given the token saw, stemming might always return saw, where lemmetization would likely return either\n",
    "# see or saw depending on whether the use of the tokenwas as a verbor a noun.as an example,consider the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i', '-->', 'i')\n",
      "('am', '-->', 'am')\n",
      "('meeting', '-->', u'meet')\n",
      "('him', '-->', 'him')\n",
      "('tomorrow', '-->', 'tomorrow')\n",
      "('in', '-->', 'in')\n",
      "('the', '-->', 'the')\n",
      "('meeting', '-->', u'meet')\n"
     ]
    }
   ],
   "source": [
    "phrase='i am meeting him tomorrow in the meeting'\n",
    "for word in phrase.split():\n",
    "    print(word,'-->',p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i', '-->', 'i')\n",
      "('am', '-->', 'am')\n",
      "('going', '-->', u'go')\n",
      "('to', '-->', 'to')\n",
      "('fishing', '-->', u'fish')\n"
     ]
    }
   ],
   "source": [
    "phrase='i am going to fishing'\n",
    "for word in phrase.split():\n",
    "    print(word,'-->',s_stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This', '-->', u'thi')\n",
      "('might', '-->', 'might')\n",
      "('be', '-->', 'be')\n",
      "('going', '-->', u'go')\n",
      "('to', '-->', 'to')\n",
      "('a', '-->', 'a')\n",
      "('huge', '-->', 'huge')\n",
      "('breakthrough', '-->', 'breakthrough')\n",
      "('in', '-->', 'in')\n",
      "('the', '-->', 'the')\n",
      "('field', '-->', 'field')\n",
      "('of', '-->', 'of')\n",
      "('artificial', '-->', u'artifici')\n",
      "('intelligence.', '-->', 'intelligence.')\n"
     ]
    }
   ],
   "source": [
    "phrase='This might be going to a huge breakthrough in the field of artificial intelligence.'\n",
    "for word in phrase.split():\n",
    "    print(word,'-->',p_stemmer.stem(word))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You', '-->', u'you')\n",
      "('should', '-->', u'should')\n",
      "('better', '-->', u'better')\n",
      "('keep', '-->', u'keep')\n",
      "('quiet', '-->', u'quiet')\n"
     ]
    }
   ],
   "source": [
    "phrase='You should better keep quiet'\n",
    "for word in phrase.split():\n",
    "    print(word,'-->',s_stem.stem(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', '-->', 'I')\n",
      "('saw', '-->', 'saw')\n",
      "('him', '-->', 'him')\n",
      "('yesterday,he', '-->', u'yesterday,h')\n",
      "('was', '-->', u'wa')\n",
      "('walking', '-->', u'walk')\n",
      "('down', '-->', 'down')\n",
      "('the', '-->', 'the')\n",
      "('street', '-->', 'street')\n",
      "('with', '-->', 'with')\n",
      "('his', '-->', u'hi')\n",
      "('friend', '-->', 'friend')\n"
     ]
    }
   ],
   "source": [
    "phrase='I saw him yesterday,he was walking down the street with his friend'\n",
    "for word in phrase.split():\n",
    "    print(word,'-->',p_stemmer.stem(word))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmetization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c spacy spacy=0.101.0 -y\n",
    "\n",
    "!python -m spacy.en.download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1=nlp(u 'John Adam is one of the researcher who invented the direction of way towards success!')\n",
    "for token in txt1:\n",
    "    print(token.text,'\\t',token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for t in text:\n",
    "        print(f '{t.text:{12}}{t.lemma_:{6}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase1=nlp('You should better keep quiet')\n",
    "show_lemmas(phrase1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase1=nlp('I am going to fishing')\n",
    "show_lemmas(phrase1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase2=nlp('This might be going to a huge breakthrough in the field of Artificial Intelligence.')\n",
    "show_lemmas(phrase2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt2=nlp(u \"Larry Page founded Google\")\n",
    "show_lemmas(txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt3=nlp(u \"I am meeting him tomorrow.Our meet is confidential\")\n",
    "show_lemmas(txt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt4=nlp(u \"Hat's off to such a great person\")\n",
    "show_lemmas(txt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
